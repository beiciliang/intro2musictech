# 总结

恭喜你！你已经完成了本书的全部内容，学习了我们准备的所有代码示例和知识材料！

在第二章中，我们对语言模型进行了全面的概述，从分词器（tokenizer）到训练方法和条件化方法，逐一分析了其关键组成部分。我们还探讨了将语言建模作为框架使用时所面临的挑战，以及在 NLP 和多模态（multimodal）领域中这些挑战目前的解决方案。

在第三章中，我们引入了音乐描述（Music Description）这一新兴的 MIR 任务。我们讨论了音乐描述的抽象性和具体性，以及语言的灵活性如何为音乐与语言模型带来独特的优势。本章追溯了方法论从分类模型到编码器-解码器架构再到音频大语言模型的演进过程，展示了该领域如何以日益复杂精妙的方式利用音乐描述。

在第四章中，我们聚焦于传统的音乐检索方法，以及音频-文本联合嵌入（joint embedding）如何帮助克服其局限性。我们探讨了使用三元组损失（triplet loss）和对比损失（contrastive loss）进行多模态度量学习的优缺点，并分析了文本编码器的进步如何增强了联合嵌入的能力。本章最后分析了联合嵌入模型的当前局限性，并探索了对话式音乐检索的可能性。

在第五章中，我们回顾了两种主流的文本生成音乐方法：基于离散 token 的语言模型和在连续空间中运行的基于扩散模型（diffusion model）的生成方法。我们还深入讨论了评估的重要性以及当前评估方法面临的挑战。

我们非常高兴你与我们一起学习了这些主题。你是否达到了学习目标？你的问题是否得到了解答？我们希望能够实现我们的目标：让这些复杂的主题对初学者更加易于理解，为数据挑战提供实用的解决方案，并弥合学术研究与实际应用之间的差距。如有任何问题或反馈，请随时与我们联系。

作为一道美味的"甜点"，我们在接下来的页面中准备了两个令人期待的未来方向。不要错过这些精彩内容！

此致，

SeungHeon, Ilaria, Zachary, JongWook, Ke
